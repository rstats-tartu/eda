---
title: "Exploratory data analysis -- Estonian cancer data"
author: "Taavi Päll"
date: "26. Sept. 2017"
bibliography: eda.bib
output: 
  html_document:
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Cancer and specially lung cancer is becoming one of the leading causes of mortality.
In year 2012. cancer claimed 8.2 million lives worldwide, European Union had 15% share (1.27 million).
Most cancer deaths are caused by lung-, liver-, stomach-, colorectal-, and breast cancer. 
Most frequent cancer types are different in females and males.
Predictions show that cancer incidence increases from 14 million in 2012. to 22 million in 2030-ties.

Vähkkasvajad on maailmas üks juhtivatest surma põhjustatavatest haigustest, nõudes 8.2 miljonit elu 2012. aastal, sealhulgas on EU-27 osakaal 2012. aastal 1.27 miljonit ehk 15%.
Kopsu-, maksa-, mao-, kolorektaal- ja rinnakasvajad põhjustavad enim vähisurmasid.
Sagedasemad vähitüübid on naistel ja meestel erinevad.
Ennustatakse et haigestumus suureneb maailmas 14 miljonilt 2012. aastal 22 miljonini 2030-ndatel.


<br>

## EDA
Exploratory data analysis is iterative process [@wickham2017r] where you:

1. Generate questions about your data.

2. Search for answers by visualising, transforming, and modelling your data.

3. Use what you learn to refine your questions and/or generate new questions.

Andmeanalüüs on iteratiivne protsess, kus:

1. Esitatakse esialgsed küsimused millele soovitakse antud andmete põhjal vastuseid;

2. Proovitakse neile küsimustele vastuseid leida, kasutades andmete visualiseerimit, transformeerimist ja modelleerimist;

3. Andmete põhjal saadud uute teadmiste najal täpsustatakse esitatavaid küsimusi ja tekivad uued küsimused [@wickham2017r].

## Questions
By using cancer incidence data from Estonian Cancer Registry we want to understand:

1. What is the cancer incidence trend in Estonia?

2. What are the most frequent cancer sites?

3. What is the most frequent cancer type in men and in women?

<br>


> However, when doing data analysis 80% of time will be spent on data munging where you also become familiar with your dataset. So it's time well spent.


## Cancer incidence data from Estonian cancer registry
Estonian cancer registry data is available via [Health statistics and health research database]( http://pxweb.tai.ee/PXWeb2015/pxweb/en/02Haigestumus/02Haigestumus__04Pahaloomulised%20kasvajad/?tablelist=true&rxid=279523e2-1ea1-4a02-920b-f85bb19a908d).
We are using cancer incidence dataset from table "PK30: Age-specific incidence rate of malignant neoplasms per 100 000 inhabitants by site and sex".

Detailed information about variables in this dataset can be found from [here](http://pxweb.tai.ee/PXWeb2015/pxweb/en/02Haigestumus/02Haigestumus__04Pahaloomulised%20kasvajad/PK30.px/?rxid=3155fc9b-3ab1-40b0-9e70-beadfb6af83c).

<br>

```{r,echo=FALSE, fig.cap="Screen caption from dataset download page. Note that data was downloaded in JSON format.", out.width=600}
knitr::include_graphics("img/pk30-page.png")
```

<br>

For your convenience, we have downloaded this dataset into ["rstats-tartu/datasets"](https://github.com/rstats-tartu/datasets) GitHub repo. 

<br>

## Create RStudio project 
Create RStudio project from GitHub repo. 
*First*, create GitHub repo and call it `eda_demo`. 
*Second*, clone this repo into RStudio project. 
Detailed instructions can be found [here](https://rstats-tartu.github.io/createrstudioprojectfromgithub/).

<br>

## Download cancer incidence dataset from GitHub
Download "cancer_incidence_PK30.json" file from "rstats-tartu/datasets" GitHub repo: 
```{r, eval=FALSE}
url <- "https://raw.githubusercontent.com/rstats-tartu/datasets/master/cancer_incidence_PK30.json"
dir.create("data")
download.file(url, "data/cancer_incidence_PK30.json")
```


<br>

## Import and prepare data

First we download "tidyverse" library. We are going to need also "stringi" and "stringr" libraries for string manipulation (you guess correctly, stringr is based on stringi):
```{r, message=FALSE}
library(tidyverse)
library(stringi)
library(stringr)
```


Then we import dataset using `json_to_df()` function from "boulder" library. 

You can install "boulder" from github "[tpall/boulder](https://github.com/tpall/boulder)":
"boulder" package has few helper functions and was created to work specificly with Estonian Health Statistics and Health Research Database.
However, "boulder" package is still under development and you should use it carefully.

```{r}
# devtools::install_github("tpall/boulder")
library(boulder)
path <- "data/cancer_incidence_PK30.json"
## json_to_df warns when data is not from Estonian Health Board
incidence <- json_to_df(path)
incidence
```

**Year, Site and Sex are factors.** 
We convert Year to numeric and Site and Sex to character using `parse_` functions from "readr" package.
```{r}
## Year to numeric
incidence <- incidence %>% mutate_at("Year", parse_number)
## Site and Sex to character
incidence <- incidence %>% mutate_at(vars(Site, Sex), parse_character)
incidence
```

<br>

>We can see that cancer incidence data is available from years `r paste(range(incidence$Year), collapse = " to ")` for both sexes, `r sum(str_detect(colnames(incidence), "^[[:digit:]]"))` age groups and `r length(unique(incidence$Site))` different types of cancer sites ...

**Hold on...** This table has data intermingled with summary data -- incidence of specific cancer types are next to total incidence -- , that's bad! 

```
Year  Site                              Sex
<fctr><fctr>                            <fctr>
2000	All malignant neoplasms (C00-C97)	Men	    <- tallies
2000	All malignant neoplasms (C00-C97)	Women	  <- tallies
2000	All malignant neoplasms except skin (other) (C00-C97, except C44)	Men	<- tallies
2000	All malignant neoplasms except skin (other) (C00-C97, except C44)	Women	<- tallies
2000	Lip, oral cavity and pharynx (C00-C14)	Men	<- tallies
2000	Lip, oral cavity and pharynx (C00-C14)	Women	<- tallies
2000	..Lip (C00)	Men	
2000	..Lip (C00)	Women	
2000	..Tongue (C01-02)	Men	
2000	..Tongue (C01-02)
```

Summaries are provided for different range of **ICD10** codes e.g. "(C00-C97)" covers all types of cancer.
We probably want to extract ICD10 codes to **identify and label summary data** so that we can decide later what we do with these rows. 


Additionally, **we have three metadata columns** in dataset called "label", "source" and "updated".

- Variable "label" says what the values are, 
- "source" gives us info about data origin and 
- "updated" is the date of the last update.


Because these three seem to be constants in our table, we want to place them into separate objects for later use in plot annotation.

```{r}
## keep label and source in a separate variables
label <- unique(incidence$label)
data_source <- unique(incidence$source)
updated <- unique(incidence$updated)
```

Table metadata shows that values are **`r tolower(label)`** and originate from **`r data_source`** and were last time updated in **`r format.Date(updated)`**.

**Extract ICD10 codes**. 
We use `extract_icd()` helper function from "boulder" package to extract ICD10 codes from Site variable.
```{r}
## Extract ICD10 codes and keep them in a separate dataframe
icd10 <- mutate(incidence, 
                icd10 = map(Site, extract_icd)) %>% 
  select(Site, icd10)
## Let's have a look, for reviewing the result we filter only short strings, note that icd10 is list column (list of character vectors)
icd10 %>% filter(str_length(Site) < 30)
```


While we are on this, we also want to trim those offending dots from beginning of names. 
We use `stri_trim_left()` from "stringi" to trim all characters from the beginning of strings **until first alphabetic character** (`?regex`).
To exclude table metadata constants, we use `select()` from "dplyr". 
```{r}
## trim characters until first [[:alpha:]], we keep also original Site values in Site_old and remove constant columns from table
incidence <- mutate(incidence, 
                    Site_old = Site,
                    Site = stri_trim_left(Site, "[[:alpha:]]")) %>% 
  select(-label, -source, -updated)
## for reviewing the result we filter only short strings
incidence %>% 
  select(Site_old, Site) %>% 
  filter(str_length(Site_old) < 20)
```

>Table is in the wide format, we want to convert it into long/tidy format and filter out missing data.


**Reshape data**.
Values are in the age group columns.
We try to reshape table such as the age groups go into "age" column and values will be in the column called "incidence".
We use `gather()` from "tidyr" library to bring age group values into one column and incidence values into the other.
Here we also need to supply the names of the value columns, otherwise `gather()` will put all categorical variables into the key column and all numeric values into value column.

```{r}
## Let's look what happens when we run gather on our data
gather(incidence)
```
Not what we want!


> It might not be always clear what `gather()` result will look like, you might need several iterations to get expected result.


**Select columns cleverly**.
Incidence data is in the age groups columns are labelled from `0-4` to `85 and older`, we need to supply the names of these columns to `gather()`.


We can do this by supplying the names of all 18 age group columns to function (risking with typos and we need to backquote these names because of dash characters) or we can **do this in the smart way**.



"dplyr" has **select helper functions** `?select_helpers` to select columns based on patterns in their names.


One such function is `matches()`: matches a regular expression (`?regex`).
Here we need to match columns with numbers in their names.
Regular expression matching zero or more numbers is `"[[:digit:]]+"`.

```{r}
colnames(incidence)
colnames(incidence) %>% matches("[[:digit:]]+", vars = .)
```


Here we use `gather()` to collect age group columns selected by `matches("[[:digit:]]+")` into columns "age" and "incidence".
```{r}
## Values are in the age group columns
incidence_long <- gather(data = incidence, 
                         key = "age", 
                         value = "incidence", 
                         matches("[[:digit:]]+"))
```

Now we have each value on separate row and can filter out missing values. Currently missing values are expicitly labeled with NA-s.
Function `complete.cases()` gives logical vector indicating rows with no missing values (no NA-s).
Based on this logical vector, `filter()` then keeps only `TRUE` rows.
```{r, echo=FALSE}
beforefilter <- nrow(incidence_long)
```


```{r}
## Filter out missing data,
incidence_long <- incidence_long %>% 
  filter(complete.cases(.))
## above is same as:
## filter(incidence_long, complete.cases(incidence_long))
```

Before filtering missing values table had `r beforefilter` rows and after `r nrow(incidence_long)`. 
**Wow, looks that we don't have NA-s in our table!**



## References
